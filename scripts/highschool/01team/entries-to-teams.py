import json
import re
from pykakasi import kakasi
from collections import OrderedDict, defaultdict

# éƒ½é“åºœçœŒå¤‰æ›ãƒãƒƒãƒ—ï¼ˆç•¥ç§° â†’ æ­£å¼åç§°ï¼‰
prefecture_map = {
    "åŒ—æµ·é“": "åŒ—æµ·é“",
    "é’æ£®": "é’æ£®çœŒ", "å²©æ‰‹": "å²©æ‰‹çœŒ", "å®®åŸ": "å®®åŸçœŒ", "ç§‹ç”°": "ç§‹ç”°çœŒ", "å±±å½¢": "å±±å½¢çœŒ", "ç¦å³¶": "ç¦å³¶çœŒ",
    "èŒ¨åŸ": "èŒ¨åŸçœŒ", "æ ƒæœ¨": "æ ƒæœ¨çœŒ", "ç¾¤é¦¬": "ç¾¤é¦¬çœŒ", "åŸ¼ç‰": "åŸ¼ç‰çœŒ", "åƒè‘‰": "åƒè‘‰çœŒ", "æ±äº¬": "æ±äº¬éƒ½", "ç¥å¥ˆå·": "ç¥å¥ˆå·çœŒ",
    "æ–°æ½Ÿ": "æ–°æ½ŸçœŒ", "å¯Œå±±": "å¯Œå±±çœŒ", "çŸ³å·": "çŸ³å·çœŒ", "ç¦äº•": "ç¦äº•çœŒ", "å±±æ¢¨": "å±±æ¢¨çœŒ", "é•·é‡": "é•·é‡çœŒ",
    "å²é˜œ": "å²é˜œçœŒ", "é™å²¡": "é™å²¡çœŒ", "æ„›çŸ¥": "æ„›çŸ¥çœŒ", "ä¸‰é‡": "ä¸‰é‡çœŒ",
    "æ»‹è³€": "æ»‹è³€çœŒ", "äº¬éƒ½": "äº¬éƒ½åºœ", "å¤§é˜ª": "å¤§é˜ªåºœ", "å…µåº«": "å…µåº«çœŒ", "å¥ˆè‰¯": "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±": "å’Œæ­Œå±±çœŒ",
    "é³¥å–": "é³¥å–çœŒ", "å³¶æ ¹": "å³¶æ ¹çœŒ", "å²¡å±±": "å²¡å±±çœŒ", "åºƒå³¶": "åºƒå³¶çœŒ", "å±±å£": "å±±å£çœŒ",
    "å¾³å³¶": "å¾³å³¶çœŒ", "é¦™å·": "é¦™å·çœŒ", "æ„›åª›": "æ„›åª›çœŒ", "é«˜çŸ¥": "é«˜çŸ¥çœŒ",
    "ç¦å²¡": "ç¦å²¡çœŒ", "ä½è³€": "ä½è³€çœŒ", "é•·å´": "é•·å´çœŒ", "ç†Šæœ¬": "ç†Šæœ¬çœŒ", "å¤§åˆ†": "å¤§åˆ†çœŒ", "å®®å´": "å®®å´çœŒ", "é¹¿å…å³¶": "é¹¿å…å³¶çœŒ",
    "æ²–ç¸„": "æ²–ç¸„çœŒ"
}

# éƒ½é“åºœçœŒ â†’ IDãƒãƒƒãƒ—
prefecture_id_map = {
    "åŒ—æµ·é“": "hokkaido", "é’æ£®çœŒ": "aomori", "å²©æ‰‹çœŒ": "iwate", "å®®åŸçœŒ": "miyagi", "ç§‹ç”°çœŒ": "akita",
    "å±±å½¢çœŒ": "yamagata", "ç¦å³¶çœŒ": "fukushima", "èŒ¨åŸçœŒ": "ibaraki", "æ ƒæœ¨çœŒ": "tochigi", "ç¾¤é¦¬çœŒ": "gunma",
    "åŸ¼ç‰çœŒ": "saitama", "åƒè‘‰çœŒ": "chiba", "æ±äº¬éƒ½": "tokyo", "ç¥å¥ˆå·çœŒ": "kanagawa", "æ–°æ½ŸçœŒ": "niigata",
    "å¯Œå±±çœŒ": "toyama", "çŸ³å·çœŒ": "ishikawa", "ç¦äº•çœŒ": "fukui", "å±±æ¢¨çœŒ": "yamanashi", "é•·é‡çœŒ": "nagano",
    "å²é˜œçœŒ": "gifu", "é™å²¡çœŒ": "shizuoka", "æ„›çŸ¥çœŒ": "aichi", "ä¸‰é‡çœŒ": "mie", "æ»‹è³€çœŒ": "shiga",
    "äº¬éƒ½åºœ": "kyoto", "å¤§é˜ªåºœ": "osaka", "å…µåº«çœŒ": "hyogo", "å¥ˆè‰¯çœŒ": "nara", "å’Œæ­Œå±±çœŒ": "wakayama",
    "é³¥å–çœŒ": "tottori", "å³¶æ ¹çœŒ": "shimane", "å²¡å±±çœŒ": "okayama", "åºƒå³¶çœŒ": "hiroshima", "å±±å£çœŒ": "yamaguchi",
    "å¾³å³¶çœŒ": "tokushima", "é¦™å·çœŒ": "kagawa", "æ„›åª›çœŒ": "ehime", "é«˜çŸ¥çœŒ": "kochi", "ç¦å²¡çœŒ": "fukuoka",
    "ä½è³€çœŒ": "saga", "é•·å´çœŒ": "nagasaki", "ç†Šæœ¬çœŒ": "kumamoto", "å¤§åˆ†çœŒ": "oita", "å®®å´çœŒ": "miyazaki",
    "é¹¿å…å³¶çœŒ": "kagoshima", "æ²–ç¸„çœŒ": "okinawa"
}

# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
with open("players.json", encoding="utf-8") as f:
    players = json.load(f)

with open("team_id_map.json", encoding="utf-8") as f:
    manual_id_map = json.load(f)

# æ—¢å­˜ã® teams.json ã‚’èª­ã¿è¾¼ã‚€
existing_ids = set()
try:
    with open("teams.json", encoding="utf-8") as f:
        existing_teams = json.load(f)
        for team in existing_teams:
            existing_ids.add(team["id"])
    print(f"ğŸ“„ æ—¢å­˜ã® teams.json ã‹ã‚‰ {len(existing_ids)} ä»¶ã® id ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
except FileNotFoundError:
    print("âš ï¸ teams.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ãƒãƒ¼ãƒ ã‚’å¯¾è±¡ã¨ã—ã¾ã™ã€‚")

# pykakasi è¨­å®š
kks = kakasi()
kks.setMode("H", "a")
kks.setMode("K", "a")
kks.setMode("J", "a")
kks.setMode("r", "Hepburn")
conv = kks.getConverter()

# ãƒ­ãƒ¼ãƒå­—IDå¤‰æ›
def to_romaji(team_name):
    name = re.sub(r"[ï¼ˆï¼‰()ãƒ»\s]", "", team_name)
    name = name.replace("é«˜ç­‰å­¦æ ¡", "").replace("é«˜æ ¡", "")
    if name in manual_id_map:
        return manual_id_map[name]
    return conv.do(name).lower().replace(" ", "-").replace("'", "")

# ãƒãƒ¼ãƒ ãƒãƒƒãƒ—ï¼ˆteamå â†’ prefectureï¼‰
team_map = {}

# å€‹äººãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠ½å‡º
for entry in players:
    for info in entry.get("information", []):
        team = info.get("team", "").strip()
        pref = info.get("prefecture", "").strip()
        if team and pref and team not in team_map:
            team_map[team] = pref

# å›£ä½“æˆ¦ã‚¨ãƒ³ãƒˆãƒªãƒ¼
for file_name in ["team_entries.json", "team_results.json"]:
    try:
        with open(file_name, encoding="utf-8") as f:
            team_entries = json.load(f)
            print(f"ğŸ“„ {file_name} ã‹ã‚‰ {len(team_entries)} ä»¶ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            for entry in team_entries:
                team = entry.get("team", "").strip()
                pref = entry.get("prefecture", "").strip()
                if team and pref and team not in team_map:
                    team_map[team] = pref
    except FileNotFoundError:
        print(f"â„¹ï¸ {file_name} ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

# é‡è¤‡IDãƒã‚§ãƒƒã‚¯ç”¨
id_counter = defaultdict(list)

# å‡ºåŠ›
with open("teams.ndjson", "w", encoding="utf-8") as f:
    for team, pref in sorted(team_map.items()):
        romaji_id = to_romaji(team)
        if romaji_id in existing_ids:
            continue  # æ—¢å­˜IDã‚¹ã‚­ãƒƒãƒ—

        id_counter[romaji_id].append(team)

        obj = OrderedDict()
        obj["id"] = romaji_id
        obj["name"] = team
        full_pref = prefecture_map.get(pref, pref)
        obj["prefecture"] = full_pref
        obj["prefectureId"] = prefecture_id_map.get(full_pref, "unknown")
        json.dump(obj, f, ensure_ascii=False)
        f.write(",\n")

print(f"âœ… åˆè¨ˆ {len(team_map)} ãƒãƒ¼ãƒ ã® teams.ndjson ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ")

# é‡è¤‡IDãƒã‚§ãƒƒã‚¯
duplicates = {k: v for k, v in id_counter.items() if len(v) > 1}
if duplicates:
    print("âš ï¸ é‡è¤‡IDãŒã‚ã‚Šã¾ã™ã€‚ç¢ºèªã—ã¦ãã ã•ã„ï¼š")
    for id_, teams in duplicates.items():
        print(f" - id: {id_} â†’ teams: {teams}")
else:
    print("âœ… IDé‡è¤‡ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
